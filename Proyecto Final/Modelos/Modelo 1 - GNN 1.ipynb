{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 16.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.10.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (2024.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\angi3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Correr para instalar, en caso de ser necesario\n",
    "!pip install torch torchvision\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angi3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.datasets import Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from PyTorch Geometric\n",
    "dataset = Amazon(root=\".\", name=\"Computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first data instance\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Loss: 2.2084, Train Acc: 37.62%, Val Acc: 37.92%\n",
      "Epoch 2/150, Loss: 6.3843, Train Acc: 15.38%, Val Acc: 15.62%\n",
      "Epoch 3/150, Loss: 3.7875, Train Acc: 26.18%, Val Acc: 25.32%\n",
      "Epoch 4/150, Loss: 2.4025, Train Acc: 21.15%, Val Acc: 18.96%\n",
      "Epoch 5/150, Loss: 2.4838, Train Acc: 49.88%, Val Acc: 47.82%\n",
      "Epoch 6/150, Loss: 2.3604, Train Acc: 47.11%, Val Acc: 46.65%\n",
      "Epoch 7/150, Loss: 2.1566, Train Acc: 43.37%, Val Acc: 43.60%\n",
      "Epoch 8/150, Loss: 2.0065, Train Acc: 51.18%, Val Acc: 50.29%\n",
      "Epoch 9/150, Loss: 1.8564, Train Acc: 58.04%, Val Acc: 56.21%\n",
      "Epoch 10/150, Loss: 1.8241, Train Acc: 51.39%, Val Acc: 50.29%\n",
      "Epoch 11/150, Loss: 1.7910, Train Acc: 48.56%, Val Acc: 48.64%\n",
      "Epoch 12/150, Loss: 1.7416, Train Acc: 45.04%, Val Acc: 45.93%\n",
      "Epoch 13/150, Loss: 1.7010, Train Acc: 54.01%, Val Acc: 54.41%\n",
      "Epoch 14/150, Loss: 1.6427, Train Acc: 56.12%, Val Acc: 55.33%\n",
      "Epoch 15/150, Loss: 1.5849, Train Acc: 50.82%, Val Acc: 49.85%\n",
      "Epoch 16/150, Loss: 1.5855, Train Acc: 53.95%, Val Acc: 54.22%\n",
      "Epoch 17/150, Loss: 1.4730, Train Acc: 55.32%, Val Acc: 54.56%\n",
      "Epoch 18/150, Loss: 1.4799, Train Acc: 60.34%, Val Acc: 59.75%\n",
      "Epoch 19/150, Loss: 1.4498, Train Acc: 69.97%, Val Acc: 69.01%\n",
      "Epoch 20/150, Loss: 1.4017, Train Acc: 68.23%, Val Acc: 66.15%\n",
      "Epoch 21/150, Loss: 1.3817, Train Acc: 66.89%, Val Acc: 64.45%\n",
      "Epoch 22/150, Loss: 1.3591, Train Acc: 68.88%, Val Acc: 67.65%\n",
      "Epoch 23/150, Loss: 1.3166, Train Acc: 69.52%, Val Acc: 68.62%\n",
      "Epoch 24/150, Loss: 1.2961, Train Acc: 69.69%, Val Acc: 68.82%\n",
      "Epoch 25/150, Loss: 1.2809, Train Acc: 70.47%, Val Acc: 68.96%\n",
      "Epoch 26/150, Loss: 1.2433, Train Acc: 71.59%, Val Acc: 69.59%\n",
      "Epoch 27/150, Loss: 1.2104, Train Acc: 72.17%, Val Acc: 69.59%\n",
      "Epoch 28/150, Loss: 1.1928, Train Acc: 71.93%, Val Acc: 69.45%\n",
      "Epoch 29/150, Loss: 1.1661, Train Acc: 72.27%, Val Acc: 70.90%\n",
      "Epoch 30/150, Loss: 1.1254, Train Acc: 72.65%, Val Acc: 71.10%\n",
      "Epoch 31/150, Loss: 1.0981, Train Acc: 73.24%, Val Acc: 71.92%\n",
      "Epoch 32/150, Loss: 1.0846, Train Acc: 73.75%, Val Acc: 72.65%\n",
      "Epoch 33/150, Loss: 1.0623, Train Acc: 73.95%, Val Acc: 73.04%\n",
      "Epoch 34/150, Loss: 1.0385, Train Acc: 74.60%, Val Acc: 73.42%\n",
      "Epoch 35/150, Loss: 1.0136, Train Acc: 74.72%, Val Acc: 72.89%\n",
      "Epoch 36/150, Loss: 0.9975, Train Acc: 74.57%, Val Acc: 72.55%\n",
      "Epoch 37/150, Loss: 0.9839, Train Acc: 74.88%, Val Acc: 72.65%\n",
      "Epoch 38/150, Loss: 0.9601, Train Acc: 75.04%, Val Acc: 73.52%\n",
      "Epoch 39/150, Loss: 0.9375, Train Acc: 75.03%, Val Acc: 73.86%\n",
      "Epoch 40/150, Loss: 0.9193, Train Acc: 75.28%, Val Acc: 73.96%\n",
      "Epoch 41/150, Loss: 0.8927, Train Acc: 68.98%, Val Acc: 67.41%\n",
      "Epoch 42/150, Loss: 0.9928, Train Acc: 75.57%, Val Acc: 75.07%\n",
      "Epoch 43/150, Loss: 0.8841, Train Acc: 73.55%, Val Acc: 72.45%\n",
      "Epoch 44/150, Loss: 0.9242, Train Acc: 74.53%, Val Acc: 73.62%\n",
      "Epoch 45/150, Loss: 0.8911, Train Acc: 75.68%, Val Acc: 73.96%\n",
      "Epoch 46/150, Loss: 0.8599, Train Acc: 76.53%, Val Acc: 74.68%\n",
      "Epoch 47/150, Loss: 0.8317, Train Acc: 77.30%, Val Acc: 75.17%\n",
      "Epoch 48/150, Loss: 0.8028, Train Acc: 77.88%, Val Acc: 76.24%\n",
      "Epoch 49/150, Loss: 0.8016, Train Acc: 77.37%, Val Acc: 75.61%\n",
      "Epoch 50/150, Loss: 0.8052, Train Acc: 78.00%, Val Acc: 76.38%\n",
      "Epoch 51/150, Loss: 0.7802, Train Acc: 78.11%, Val Acc: 77.40%\n",
      "Epoch 52/150, Loss: 0.7533, Train Acc: 78.98%, Val Acc: 78.32%\n",
      "Epoch 53/150, Loss: 0.7423, Train Acc: 79.66%, Val Acc: 78.81%\n",
      "Epoch 54/150, Loss: 0.7326, Train Acc: 79.52%, Val Acc: 78.71%\n",
      "Epoch 55/150, Loss: 0.7230, Train Acc: 79.11%, Val Acc: 78.23%\n",
      "Epoch 56/150, Loss: 0.7151, Train Acc: 79.45%, Val Acc: 78.47%\n",
      "Epoch 57/150, Loss: 0.6974, Train Acc: 80.10%, Val Acc: 78.71%\n",
      "Epoch 58/150, Loss: 0.6780, Train Acc: 79.95%, Val Acc: 78.71%\n",
      "Epoch 59/150, Loss: 0.6748, Train Acc: 79.85%, Val Acc: 78.03%\n",
      "Epoch 60/150, Loss: 0.6725, Train Acc: 80.63%, Val Acc: 79.19%\n",
      "Epoch 61/150, Loss: 0.6585, Train Acc: 82.08%, Val Acc: 80.60%\n",
      "Epoch 62/150, Loss: 0.6452, Train Acc: 82.66%, Val Acc: 81.38%\n",
      "Epoch 63/150, Loss: 0.6360, Train Acc: 82.94%, Val Acc: 82.20%\n",
      "Epoch 64/150, Loss: 0.6291, Train Acc: 83.18%, Val Acc: 81.72%\n",
      "Epoch 65/150, Loss: 0.6235, Train Acc: 82.69%, Val Acc: 81.57%\n",
      "Epoch 66/150, Loss: 0.6153, Train Acc: 82.24%, Val Acc: 81.62%\n",
      "Epoch 67/150, Loss: 0.6068, Train Acc: 82.43%, Val Acc: 81.47%\n",
      "Epoch 68/150, Loss: 0.6007, Train Acc: 83.22%, Val Acc: 82.01%\n",
      "Epoch 69/150, Loss: 0.5940, Train Acc: 83.75%, Val Acc: 82.30%\n",
      "Epoch 70/150, Loss: 0.5870, Train Acc: 84.44%, Val Acc: 83.07%\n",
      "Epoch 71/150, Loss: 0.5812, Train Acc: 84.75%, Val Acc: 83.66%\n",
      "Epoch 72/150, Loss: 0.5749, Train Acc: 84.82%, Val Acc: 83.80%\n",
      "Epoch 73/150, Loss: 0.5689, Train Acc: 84.53%, Val Acc: 83.75%\n",
      "Epoch 74/150, Loss: 0.5650, Train Acc: 84.49%, Val Acc: 83.75%\n",
      "Epoch 75/150, Loss: 0.5602, Train Acc: 84.78%, Val Acc: 83.95%\n",
      "Epoch 76/150, Loss: 0.5532, Train Acc: 85.04%, Val Acc: 84.24%\n",
      "Epoch 77/150, Loss: 0.5479, Train Acc: 85.23%, Val Acc: 84.34%\n",
      "Epoch 78/150, Loss: 0.5447, Train Acc: 85.20%, Val Acc: 84.09%\n",
      "Epoch 79/150, Loss: 0.5404, Train Acc: 85.09%, Val Acc: 84.24%\n",
      "Epoch 80/150, Loss: 0.5355, Train Acc: 85.25%, Val Acc: 84.19%\n",
      "Epoch 81/150, Loss: 0.5310, Train Acc: 85.51%, Val Acc: 84.72%\n",
      "Epoch 82/150, Loss: 0.5268, Train Acc: 85.84%, Val Acc: 84.72%\n",
      "Epoch 83/150, Loss: 0.5234, Train Acc: 86.04%, Val Acc: 84.77%\n",
      "Epoch 84/150, Loss: 0.5196, Train Acc: 86.07%, Val Acc: 84.82%\n",
      "Epoch 85/150, Loss: 0.5154, Train Acc: 85.75%, Val Acc: 85.31%\n",
      "Epoch 86/150, Loss: 0.5120, Train Acc: 85.80%, Val Acc: 85.16%\n",
      "Epoch 87/150, Loss: 0.5086, Train Acc: 85.84%, Val Acc: 85.26%\n",
      "Epoch 88/150, Loss: 0.5051, Train Acc: 86.15%, Val Acc: 85.45%\n",
      "Epoch 89/150, Loss: 0.5020, Train Acc: 86.36%, Val Acc: 85.55%\n",
      "Epoch 90/150, Loss: 0.4986, Train Acc: 86.32%, Val Acc: 85.60%\n",
      "Epoch 91/150, Loss: 0.4953, Train Acc: 86.35%, Val Acc: 85.45%\n",
      "Epoch 92/150, Loss: 0.4926, Train Acc: 86.40%, Val Acc: 85.45%\n",
      "Epoch 93/150, Loss: 0.4897, Train Acc: 86.57%, Val Acc: 85.31%\n",
      "Epoch 94/150, Loss: 0.4865, Train Acc: 86.66%, Val Acc: 85.31%\n",
      "Epoch 95/150, Loss: 0.4837, Train Acc: 86.61%, Val Acc: 85.45%\n",
      "Epoch 96/150, Loss: 0.4810, Train Acc: 86.53%, Val Acc: 85.50%\n",
      "Epoch 97/150, Loss: 0.4784, Train Acc: 86.64%, Val Acc: 85.60%\n",
      "Epoch 98/150, Loss: 0.4757, Train Acc: 86.79%, Val Acc: 85.65%\n",
      "Epoch 99/150, Loss: 0.4731, Train Acc: 86.87%, Val Acc: 85.45%\n",
      "Epoch 100/150, Loss: 0.4706, Train Acc: 86.91%, Val Acc: 85.40%\n",
      "Epoch 101/150, Loss: 0.4681, Train Acc: 87.06%, Val Acc: 85.35%\n",
      "Epoch 102/150, Loss: 0.4656, Train Acc: 87.05%, Val Acc: 85.60%\n",
      "Epoch 103/150, Loss: 0.4633, Train Acc: 87.06%, Val Acc: 85.60%\n",
      "Epoch 104/150, Loss: 0.4610, Train Acc: 87.05%, Val Acc: 85.60%\n",
      "Epoch 105/150, Loss: 0.4587, Train Acc: 87.10%, Val Acc: 85.65%\n",
      "Epoch 106/150, Loss: 0.4565, Train Acc: 87.11%, Val Acc: 85.65%\n",
      "Epoch 107/150, Loss: 0.4543, Train Acc: 87.17%, Val Acc: 85.74%\n",
      "Epoch 108/150, Loss: 0.4521, Train Acc: 87.31%, Val Acc: 85.74%\n",
      "Epoch 109/150, Loss: 0.4499, Train Acc: 87.33%, Val Acc: 85.65%\n",
      "Epoch 110/150, Loss: 0.4478, Train Acc: 87.38%, Val Acc: 85.65%\n",
      "Epoch 111/150, Loss: 0.4458, Train Acc: 87.36%, Val Acc: 85.84%\n",
      "Epoch 112/150, Loss: 0.4438, Train Acc: 87.37%, Val Acc: 85.98%\n",
      "Epoch 113/150, Loss: 0.4418, Train Acc: 87.38%, Val Acc: 85.84%\n",
      "Epoch 114/150, Loss: 0.4398, Train Acc: 87.51%, Val Acc: 85.69%\n",
      "Epoch 115/150, Loss: 0.4379, Train Acc: 87.58%, Val Acc: 85.79%\n",
      "Epoch 116/150, Loss: 0.4360, Train Acc: 87.56%, Val Acc: 85.84%\n",
      "Epoch 117/150, Loss: 0.4341, Train Acc: 87.63%, Val Acc: 86.08%\n",
      "Epoch 118/150, Loss: 0.4322, Train Acc: 87.66%, Val Acc: 86.18%\n",
      "Epoch 119/150, Loss: 0.4304, Train Acc: 87.68%, Val Acc: 86.23%\n",
      "Epoch 120/150, Loss: 0.4286, Train Acc: 87.79%, Val Acc: 86.18%\n",
      "Epoch 121/150, Loss: 0.4269, Train Acc: 87.76%, Val Acc: 86.13%\n",
      "Epoch 122/150, Loss: 0.4251, Train Acc: 87.77%, Val Acc: 86.23%\n",
      "Epoch 123/150, Loss: 0.4234, Train Acc: 87.80%, Val Acc: 86.37%\n",
      "Epoch 124/150, Loss: 0.4217, Train Acc: 87.87%, Val Acc: 86.42%\n",
      "Epoch 125/150, Loss: 0.4200, Train Acc: 87.92%, Val Acc: 86.42%\n",
      "Epoch 126/150, Loss: 0.4183, Train Acc: 87.99%, Val Acc: 86.47%\n",
      "Epoch 127/150, Loss: 0.4167, Train Acc: 87.99%, Val Acc: 86.66%\n",
      "Epoch 128/150, Loss: 0.4150, Train Acc: 88.04%, Val Acc: 86.66%\n",
      "Epoch 129/150, Loss: 0.4134, Train Acc: 88.12%, Val Acc: 86.57%\n",
      "Epoch 130/150, Loss: 0.4118, Train Acc: 88.12%, Val Acc: 86.52%\n",
      "Epoch 131/150, Loss: 0.4103, Train Acc: 88.17%, Val Acc: 86.71%\n",
      "Epoch 132/150, Loss: 0.4087, Train Acc: 88.18%, Val Acc: 86.76%\n",
      "Epoch 133/150, Loss: 0.4072, Train Acc: 88.23%, Val Acc: 86.81%\n",
      "Epoch 134/150, Loss: 0.4056, Train Acc: 88.27%, Val Acc: 86.91%\n",
      "Epoch 135/150, Loss: 0.4041, Train Acc: 88.30%, Val Acc: 87.00%\n",
      "Epoch 136/150, Loss: 0.4027, Train Acc: 88.33%, Val Acc: 87.00%\n",
      "Epoch 137/150, Loss: 0.4012, Train Acc: 88.33%, Val Acc: 87.05%\n",
      "Epoch 138/150, Loss: 0.3998, Train Acc: 88.40%, Val Acc: 87.10%\n",
      "Epoch 139/150, Loss: 0.3983, Train Acc: 88.43%, Val Acc: 87.20%\n",
      "Epoch 140/150, Loss: 0.3969, Train Acc: 88.45%, Val Acc: 87.25%\n",
      "Epoch 141/150, Loss: 0.3955, Train Acc: 88.45%, Val Acc: 87.25%\n",
      "Epoch 142/150, Loss: 0.3941, Train Acc: 88.49%, Val Acc: 87.34%\n",
      "Epoch 143/150, Loss: 0.3927, Train Acc: 88.50%, Val Acc: 87.44%\n",
      "Epoch 144/150, Loss: 0.3914, Train Acc: 88.51%, Val Acc: 87.44%\n",
      "Epoch 145/150, Loss: 0.3900, Train Acc: 88.51%, Val Acc: 87.49%\n",
      "Epoch 146/150, Loss: 0.3887, Train Acc: 88.52%, Val Acc: 87.49%\n",
      "Epoch 147/150, Loss: 0.3874, Train Acc: 88.53%, Val Acc: 87.54%\n",
      "Epoch 148/150, Loss: 0.3861, Train Acc: 88.55%, Val Acc: 87.58%\n",
      "Epoch 149/150, Loss: 0.3848, Train Acc: 88.59%, Val Acc: 87.68%\n",
      "Epoch 150/150, Loss: 0.3835, Train Acc: 88.61%, Val Acc: 87.78%\n",
      "\n",
      "Final Test Accuracy: 88.13%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Definir el modelo GNN\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_units, out_features):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_features, hidden_units)\n",
    "        self.conv2 = GCNConv(hidden_units, out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Fijar la semilla\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Definir el tamaño de cada subconjunto\n",
    "num_nodes = data.num_nodes\n",
    "train_size = int(0.7 * num_nodes)\n",
    "val_size = int(0.15 * num_nodes)\n",
    "test_size = num_nodes - train_size - val_size\n",
    "\n",
    "# Realizar la división usando random_split\n",
    "indices = torch.randperm(num_nodes)\n",
    "train_indices, val_indices, test_indices = torch.split(indices, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear máscaras de entrenamiento, validación y prueba\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_indices] = True\n",
    "\n",
    "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.val_mask[val_indices] = True\n",
    "\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_indices] = True\n",
    "\n",
    "# Inicializar el modelo, el criterio de pérdida y el optimizador\n",
    "gnn = GNN(dataset.num_features, hidden_units=64, out_features=dataset.num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gnn.parameters(), lr=0.01)\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train(model1, data):\n",
    "    model1.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model1(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Función de evaluación\n",
    "def evaluate(model1, data, mask):\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model1(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred[mask] == data.y[mask]).sum().item()\n",
    "        accuracy = correct / mask.sum().item()\n",
    "    return accuracy\n",
    "\n",
    "# Entrenar el modelo\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(gnn, data)\n",
    "    train_acc = evaluate(gnn, data, data.train_mask)\n",
    "    val_acc = evaluate(gnn, data, data.val_mask)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "# Evaluar el modelo final en el conjunto de prueba\n",
    "test_acc = evaluate(gnn, data, data.test_mask)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
